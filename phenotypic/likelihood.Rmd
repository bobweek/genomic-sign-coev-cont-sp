---
title: "Likelihood of Heirarchical Matern Gaussian Random Field"
header-includes:
  - \usepackage{amsmath}
  - \usepackage{dutchcal}
  - \usepackage{mathrsfs}
  - \usepackage{csquotes}
  - \usepackage{textcomp}
  - \usepackage[T3,T1]{fontenc}
  - \DeclareSymbolFont{tipa}{T3}{cmr}{m}{n}
  - \DeclareMathAccent{\invbreve}{\mathalpha}{tipa}{16}
output: pdf_document
editor_options: 
  chunk_output_type: console
---

We model trait values of individuals as independent normally distributed variables around a mean $\bar z$ with variance $v$. In turn the mean $\bar z$ is a function of location $\pmb x=(x_1,x_2)^\top$ and follows a stationary Gaussian random field with spatially homogeneous mean $\tilde z$ and Matern covariance $C(d)$ with collocated variance $V=C(0)$, characteristic length $\xi$ and smoothness parameter $\nu=1$. Hence, observed individual trait values $z_1$ and $z_2$ at locations $\pmb x_1,\pmb x_2$ separated at a distance $d$ will be bivariate normally distributed with the following statistical properties:

$$\mathbb Ez_1=\mathbb Ez_2=\tilde z, \ \mathbb Vz_1=\mathbb Vz_2=v+V, \mathbb C(z_1,z_2)=C(d),$$

$$\mathbb E(z_i|\bar z)=\bar z(\pmb x_i), \ \mathbb V(z_i|\bar z)=v, \ \mathbb C(z_1,z_2|\bar z)=0.$$

Since we only get a single sample of this random field, the likelihood function is just

$$L(\tilde z,v,V,\xi|\pmb z)=\frac{1}{\sqrt{(2\pi)^n|\Sigma|}}\exp\left(-\frac{1}{2}(\pmb z-\pmb{\tilde z})\Sigma^{-1}(\pmb z-\pmb{\tilde z})^\top\right),$$

where $\pmb z=(z_1,\dots,z_n)^\top$ is the vector of observed individual trait values (here there are $n$ individuals) observed at locations $\pmb x_1,\dots,\pmb x_n$, $\pmb{\tilde z}$ is the vector of expected trait values $(\tilde z,\dots,\tilde z)^\top$ and $\Sigma$ is a covariance matrix with $v+V$ on the diagonal and $C(\|\pmb x_i-\pmb x_j\|)$ on the $i,j$th off-diagonal entry.

To maximize likelihood, we first compute gradients of the log-likelihood $\ell=\ln L$ with respect to model parameters. We then solve for the parameter values when those gradients are zero:

$$\frac{\partial\ell}{\partial\tilde z}=-\frac{1}{2}\frac{\partial}{\partial\tilde z}\left[(\pmb z-\pmb{\tilde z})\Sigma^{-1}(\pmb z-\pmb{\tilde z})^\top\right]=-\frac{1}{2}\frac{\partial}{\partial\tilde z}\sum_{ij}(\sigma^{-1})_{ij}(z_i-\tilde z)(z_j-\tilde z)$$

$$=\sum_{ij}(\sigma^{-1})_{ij}\Big(\tfrac{z_i+z_j}{2}-\tilde z\Big)=\sum_{ij}\tfrac{z_i+z_j}{2}(\sigma^{-1})_{ij}-\tilde z\sum_{ij}(\sigma^{-1})_{ij},$$

$$\implies \hat{\tilde z}=\frac{\sum_{ij}\tfrac{z_i+z_j}{2}(\sigma^{-1})_{ij}}{\sum_{ij}(\sigma^{-1})_{ij}}.$$

Unfortunately, the rest is analytically intractable. So we proceed via numerical optimization to maximize likelihood... in julia... then import the results below.

```{r, echo=F}
mle = read.csv("likelihood/mle.csv")
input = read.csv("likelihood/input.csv")

mlmeans.v = c()
mlmeans.V = c()
mlmeans.ξ = c()
for(i in 27:54){
  mlmeans.v = c( mlmeans.v, mean(mle$v[which(mle$id==i & mle$v!=Inf)]) )
  mlmeans.V = c( mlmeans.V, mean(mle$V[which(mle$id==i & mle$V!=Inf)]) )
  mlmeans.ξ = c( mlmeans.ξ, mean(mle$ξ[which(mle$id==i & mle$ξ!=Inf)]) )
}

inpt = subset(input,id%in%(27:54))

plot(inpt$v,mlmeans.v, log="xy")
abline(0,1)

plot(inpt$V,mlmeans.V, log="xy")
abline(0,1)

plot(inpt$ξ,mlmeans.ξ,ylim=c(0.08,1), log="xy")
abline(0,1)
```

